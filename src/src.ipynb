{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Paper:\n",
    "    BASE_URL = \"https://api.semanticscholar.org/v1/paper/\"\n",
    "    CITATION_LIMIT = 10\n",
    "    paper_id: str\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.url = f'{self.BASE_URL}{self.paper_id}'\n",
    "        self.paper = requests.get(self.url).json()\n",
    "    \n",
    "    @property\n",
    "    def id(self) -> str:\n",
    "        return self.paper_id\n",
    "    \n",
    "    @property\n",
    "    def title(self) -> str:\n",
    "        return self.paper['title']\n",
    "        \n",
    "    @property\n",
    "    def abstract(self) -> str:\n",
    "        return self.paper['abstract']\n",
    "    \n",
    "    @property\n",
    "    def citations(self) -> List[str]:\n",
    "        citations = []\n",
    "        for c in self.paper['citations'][:self.CITATION_LIMIT]:\n",
    "            citations.append(c[\"paperId\"])\n",
    "\n",
    "        return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Paper(\"d4b651d6a904f69f8fa1dcad4ebe972296af3a9a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d4b651d6a904f69f8fa1dcad4ebe972296af3a9a'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Identifying Relations for Open Information Extraction'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"Open Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a pre-specified vocabulary. This paper shows that the output of state-of-the-art Open IE systems is rife with uninformative and incoherent extractions. To overcome these problems, we introduce two simple syntactic and lexical constraints on binary relations expressed by verbs. We implemented the constraints in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos. More than 30% of ReVerb's extractions are at precision 0.8 or higher---compared to virtually none for earlier systems. The paper concludes with a detailed analysis of ReVerb's errors, suggesting directions for future work.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a1d49c5ea00831d540f027c0c009cacd2c21f3b5',\n",
       " '9ea5874d261359e287eabb735de38a8edba1e091',\n",
       " '032244fb8ff881f4f12345e9afc7ea5627952f4a',\n",
       " '279cc657655eeb4e96a2eaf3d77f708edbf6a313',\n",
       " '47a541269d4ef70f37f0d3a57483312c4c6c2ad5',\n",
       " 'd582909be7ad3ca80fcfca3e1d9ced2e60966db2',\n",
       " '28fdb929d1c4f87bbb9cc0b5bb880567e3c50429',\n",
       " '1f872354e0cfde91e86e68b35d89a6d447f48936',\n",
       " 'bdb32ea23986f6dfe436c5dba0d13e95dea07c92',\n",
       " 'fda21913e8d889a84677f96231a145ecf2c206a2']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.id\n",
    "p.title\n",
    "p.abstract\n",
    "p.citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = {}\n",
    "\n",
    "queue = []\n",
    "while True:\n",
    "    for s in p.citations:\n",
    "        if s not in papers:\n",
    "            papers[s] = Paper(s)\n",
    "            queue.append(papers[s])\n",
    "            \n",
    "    if queue:\n",
    "        p = queue.pop()\n",
    "    else:\n",
    "        break\n",
    "    if len(papers) == 1000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paper(paper_id='a1d49c5ea00831d540f027c0c009cacd2c21f3b5')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(papers.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indexerror' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mget_paper_info\u001b[0;34m(paper_id, option)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     citations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaperid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m indexerror:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'paperid'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid option\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Testing Function\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m cit \u001b[38;5;241m=\u001b[39m \u001b[43mget_paper_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md4b651d6a904f69f8fa1dcad4ebe972296af3a9a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     53\u001b[0m get_paper_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md4b651d6a904f69f8fa1dcad4ebe972296af3a9a\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m get_paper_info(\u001b[38;5;28mstr\u001b[39m(cit), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m, in \u001b[0;36mget_paper_info\u001b[0;34m(paper_id, option)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         citations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcitations\u001b[39m\u001b[38;5;124m\"\u001b[39m][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaperid\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mindexerror\u001b[49m:\n\u001b[1;32m     36\u001b[0m         citations\u001b[38;5;241m.\u001b[39mappend(none)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# return the options\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indexerror' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up an API query to the Semantic Scholar API\n",
    "# to get the paper with the given ID\n",
    "# and print the title of the paper\n",
    "# along with its abstract and the titles of the\n",
    "# first 10 papers it cites\n",
    "\n",
    "\n",
    "def get_paper_info(paper_id, option):\n",
    "    #possible options include: id, title, abstract text, citations\n",
    "    \n",
    "    # Set the base URL for the Semantic Scholar API\n",
    "    base_url = \"https://api.semanticscholar.org/v1/paper/\"\n",
    "\n",
    "    # Set the full URL for the API query\n",
    "    url = base_url + paper_id\n",
    "\n",
    "    # Query the API\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Convert the response to JSON\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    # Print the title of the paper\n",
    "    title = str(data[\"title\"])\n",
    "\n",
    "    # Print the abstract of the paper\n",
    "    abstract = str(data[\"abstract\"])\n",
    "\n",
    "    # Put the first 10 paper IDs in an array\n",
    "    # and if there's an error, append `None\n",
    "    citations = []\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            citations.append(str(data[\"citations\"][i][\"paperid\"]))\n",
    "        except indexerror:\n",
    "            citations.append(none)\n",
    "\n",
    "    # return the options\n",
    "    if option == \"id\":\n",
    "        return paper_id\n",
    "    elif option == \"title\":\n",
    "        return title\n",
    "    elif option == \"abstract\":\n",
    "        return abstract\n",
    "    elif option == \"citations\":\n",
    "        return citations\n",
    "    else:\n",
    "        return \"Invalid option\"\n",
    "\n",
    "# Testing Function\n",
    "cit = get_paper_info(\"d4b651d6a904f69f8fa1dcad4ebe972296af3a9a\", \"citations\")[0]\n",
    "\n",
    "get_paper_info(\"d4b651d6a904f69f8fa1dcad4ebe972296af3a9a\", \"title\")\n",
    "get_paper_info(str(cit), \"title\")\n",
    "get_paper_info(str(cit), \"citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_challenge_words(abstractString: str):\n",
    "    # Given an abstract,\n",
    "    # Returns array of strings of challenging words in the form:\n",
    "    # ['Active Galactic Nuclei', 'BPT classification', 'Quenching scenarios', ...]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardest words:  ['actively', 'typically', 'diagnostics', 'hosted', 'luminous', 'revisit', 'incompleteness', 'interestingly', 'consistently', 'unprecedented', 'redshifts', 'revisiting', 'diagnostics']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def hardest_words_synonym(text):\n",
    "    # This function extracts the hardest words\n",
    "    # Using the number of synonyms as a proxy\n",
    "    # for the level of difficulty of the word\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    filtered_words = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Identify the hardest words\n",
    "    hardest_words = []\n",
    "    for word in filtered_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if len(synonyms) == 1:\n",
    "            hardest_words.append(word)\n",
    "\n",
    "    return hardest_words\n",
    "\n",
    "# Input text\n",
    "text = \"Nebular He iiùúÜ4686√Ö line emission is useful to unveil active galactic nuclei (AGN) residing in actively star-forming (SF) galaxies, typically missed by the standard BPT classification. Here we adopt the He ii diagnostic to identify hidden AGN in the Local Universe using for the first time spatially-resolved data from the Data Release 15 of the Mapping Nearby Galaxies at APO survey (MaNGA DR15). By combining results from He ii and BPT diagnostics, we overall select 459 AGN host candidates (‚àº10% in MaNGA DR15), out of which 27 are identified as AGN by the He ii diagram only. The He ii-only AGN population is hosted by massive (M‚àó & 1010 M\f",
    ") SF Main Sequence galaxies, and on average less luminous than the BPT-selected AGN. Given the He ii line faintness, we revisit our census accounting for incompleteness effects due to the He ii sensitivity limit of MaNGA. We thus obtain an overall increased fraction (11%) of AGN in MaNGA compared to the BPT-only census (9%), which further increases to 14% for galaxies more massive than 1010 M\f",
    "; interestingly, on the SF Main Sequence the increase is by about a factor of 2. A substantial number of AGN in SF galaxies points to significant, coeval star formation and black hole accretion, consistently with results from hydrodynamical simulations and with important implications on quenching scenarios. In view of exploring unprecedented high redshifts with JWST and new ground-based facilities, revisiting the standard BPT classification through novel emission-line diagnostics is fundamental to discover AGN in highly SF environments.\"\n",
    "\n",
    "# Find the hardest words\n",
    "hardest = hardest_words(text)\n",
    "\n",
    "# Print the hardest words\n",
    "print(\"Hardest words: \", hardest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dj/yd_369kx231256n8rxsw9wlh0000gn/T/ipykernel_79114/784261223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
